{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FilipeChagasDev/Facial-Recognition-ResNet50-SNN/blob/main/training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoKiDL29vrZb"
      },
      "source": [
        "# Siamese Neural Network (SNN) training with ResNet50 encoder\n",
        "\n",
        "This notebook trains the SNN with ResNet50 encoder for facial recognition applications.\n",
        "\n",
        "## What is a Siamese Neural Network\n",
        "\n",
        "Siamese neural network (SNN) is an architecture proposed by Bromley et al in 1994. The initial objective of this architecture was to create signature recognizers, but the possibilities of this architecture are wide. In general, it is an option to solve pattern recognition problems where there is no closed and pre-defined set of classes.\n",
        "\n",
        "The structure of an SNN can be defined as follows.\n",
        "\n",
        "$$y = d(f(a), f(b))$$\n",
        "\n",
        "Where:\n",
        "* $a$ and $b$ are input tensors. RGB images are typically third-order tensors.\n",
        "* $f$ in the encoder function. The purpose of this function is to transform the input tensors into feature vectors. This function is non-linear.\n",
        "* $d$ is the distance function. The purpose of this function is to calculate the distance between the feature vectors. Herein, euclidean distance is used as $d$. \n",
        "* $y$ is the SNN output.\n",
        "\n",
        "The SNN is trained with pairs of tensors $(a,b)$ as input, that are labeled as **1** (genuine) or **0** (impostor). The pair $(a,b)$ is genuine only if $a$ and $b$ belong to the same class. In the training process, $d(f(a), f(b))$ is conditioned to give low distances to genuine pairs and high distances to impostor pairs.\n",
        "\n",
        "## What is a perfect SNN\n",
        "\n",
        "A trained SNN can be considered perfect if satisfy the following condition.\n",
        "\n",
        "* $d(f(a_1), f(b_1)) < d(f(a_2), f(d_2))$ for any genuine pair $(a_1, b_1)$ and any impostor pair $(a_2, b_2)$.\n",
        "\n",
        "Hardly a training process results in a perfect SNN. In real situations, we just want $d(f(a_1), f(b_1)) < d(f(a_2), f(d_2))$ for most genuine pairs $(a_1, b_1)$ and for most imposter pairs $(a_2, b_2)$.\n",
        "\n",
        "## SNN for facial recognition\n",
        "\n",
        "In this work, we are going to train the SNN with pairs of cropped face photos from the CelebA dataset. Pairs of photos of the same person are genuine, and pairs of photos of different people are imposters.\n",
        "\n",
        "## Code\n",
        "\n",
        "To run this notebook on Google Colab, you will need to upload files:\n",
        "\n",
        "* helper.py\n",
        "* pairing.py\n",
        "* partitioning.py\n",
        "* snn.py "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYXTTnPYvrZf"
      },
      "source": [
        "First, the necessary modules will be included."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwVfL_3tvrZg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "import helper\n",
        "from snn import SNNGenerator, SNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAQh1ZO9vrZi"
      },
      "source": [
        "Now, CelebA will be downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AxHNQNnvrZj"
      },
      "outputs": [],
      "source": [
        "helper.download_celeba()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkWxoHelvrZk"
      },
      "source": [
        "Now, **training** and **validation** partitions will be created. The **build_celeba_partitions** function generates the **celeba_partitions/partitions.json** file that separates the **validation** people from the **training** people. Validation and training are make with photos of different persons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQ-DvpBmvrZl"
      },
      "outputs": [],
      "source": [
        "from partitioning import build_celeba_partitions\n",
        "build_celeba_partitions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEo3pAzVvrZm"
      },
      "source": [
        "Now the next code cell generates the paired image metadata. It might take a while.\n",
        "\n",
        "The *build_celeba_pairs* function generates four CSV files: *eval_genuine_pairs.csv*, *eval_impostor_pairs.csv*, *training_genuine_pairs.csv* and *training_impostor_pairs.csv*. These files have the following format:\n",
        "\n",
        "|file_a|person_a|file_b|person_b|\n",
        "|:----:|:------:|:----:|:------:|\n",
        "| ...  | ...    | ...  | ...    |\n",
        "\n",
        "* The **file_a** column has photo filenames $a$.\n",
        "* The **person_a** column has person identifiers $a$. Each person is identified by an integer greater than 0.\n",
        "* The **file_b** column has photo filenames $b$.\n",
        "* The **person_b** column has person identifiers $b$.\n",
        "\n",
        "In files *eval_impostor_pairs.csv* and *training_impostor_pairs.csv*, all the rows have different values for *person_a* and *person_b*. In files *eval_genuine_pairs.csv* and *training_impostor_pairs.csv*, all the rows have equal values for *person_a* and *person_b*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7Dlh7qDvrZo"
      },
      "outputs": [],
      "source": [
        "from pairing import build_celeba_pairs\n",
        "build_celeba_pairs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0M7dVnCvrZp"
      },
      "source": [
        "The following function loads a batch of images and formats them to the encoder.\n",
        "\n",
        "* Width: 80px\n",
        "* Height: 80px\n",
        "* Format: RGB (3 channels)\n",
        "* Data type: Unitary floats (between 0 and 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpgGTkJ4vrZq"
      },
      "outputs": [],
      "source": [
        "def load_images(paths):\n",
        "    images = [helper.get_image(path, 80, 80, 'RGB').astype(np.float)/255 for path in paths]\n",
        "    return np.array(images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgni0KO1vrZr"
      },
      "source": [
        "The next cell loads the CSVs generated by *build_celeba_pairs*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ta80GbzvrZr"
      },
      "outputs": [],
      "source": [
        "training_genuine_pairs = pd.read_csv(os.path.join('celeba_pairs', 'training_genuine_pairs.csv'))\n",
        "training_impostor_pairs = pd.read_csv(os.path.join('celeba_pairs', 'training_impostor_pairs.csv'))\n",
        "eval_genuine_pairs = pd.read_csv(os.path.join('celeba_pairs', 'eval_genuine_pairs.csv'))\n",
        "eval_impostor_pairs = pd.read_csv(os.path.join('celeba_pairs', 'eval_impostor_pairs.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H49KxAYsvrZs"
      },
      "source": [
        "CelebA is a big dataset. To reduce the amount of time needed to train the SNN, it is necessary to randomly sample data from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBarWAN4vrZt"
      },
      "outputs": [],
      "source": [
        "divider = 10\n",
        "training_genuine_pairs = training_genuine_pairs.sample(n=training_genuine_pairs.shape[0]//divider, random_state=1)\n",
        "training_impostor_pairs = training_impostor_pairs.sample(n=training_impostor_pairs.shape[0]//divider, random_state=1)\n",
        "eval_genuine_pairs = eval_genuine_pairs.sample(n=eval_genuine_pairs.shape[0]//divider, random_state=1)\n",
        "eval_impostor_pairs = eval_impostor_pairs.sample(n=eval_impostor_pairs.shape[0]//divider, random_state=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1TrylQ6vrZu"
      },
      "source": [
        "The next cell implements the data generator needed to train the SNN. The generator is a class that loads and formats the images of each training batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7DheuJAvrZv"
      },
      "outputs": [],
      "source": [
        "import h5py as h5\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CelebAGenerator(SNNGenerator):\n",
        "    def __init__(self, name: str, genuine_pairs_df: pd.DataFrame, impostor_pairs_df: pd.DataFrame, batch_size: int):\n",
        "        self.__genuine_pairs_df__ = genuine_pairs_df\n",
        "        self.__impostor_pairs_df__ = impostor_pairs_df\n",
        "        self.__batch_size__ = batch_size\n",
        "        self.__name__ = name\n",
        "        self.__n_batches__ = (self.__genuine_pairs_df__.shape[0]+self.__impostor_pairs_df__.shape[0])//self.__batch_size__\n",
        "        \n",
        "        if not os.path.exists(name):\n",
        "            os.mkdir(name)\n",
        "            print('Generating batches for', name)\n",
        "            self.__batches__ = [self.get_batch(i) for i in tqdm(range(self.__n_batches__))]\n",
        "        else:\n",
        "            print('Loading batches for', name)\n",
        "            self.__batches__ = [h5.File(os.path.join(self.__name__, f'b{i}.h5'), 'r') for i in tqdm(range(self.__n_batches__))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.__n_batches__\n",
        "\n",
        "    def get_batch(self, index):\n",
        "        def get_genuines():\n",
        "            my_rows = self.__genuine_pairs_df__.sample(n=self.__batch_size__//2, replace=False)\n",
        "            images_a = load_images([os.path.join('celeba', 'img_align_celeba', fn) for fn in list(my_rows['file_a'])])\n",
        "            images_b = load_images([os.path.join('celeba', 'img_align_celeba', fn) for fn in list(my_rows['file_b'])])\n",
        "            images_y = np.ones(shape=(self.__batch_size__//2,1))\n",
        "            return images_a, images_b, images_y\n",
        "\n",
        "        def get_impostors():\n",
        "            my_rows = self.__impostor_pairs_df__.sample(n=self.__batch_size__//2, replace=False)\n",
        "            images_a = load_images([os.path.join('celeba', 'img_align_celeba', fn) for fn in list(my_rows['file_a'])])\n",
        "            images_b = load_images([os.path.join('celeba', 'img_align_celeba', fn) for fn in list(my_rows['file_b'])])\n",
        "            images_y = np.zeros(shape=(self.__batch_size__//2,1))\n",
        "            return images_a, images_b, images_y\n",
        "\n",
        "        genuines_a, genuines_b, genuines_y = get_genuines()\n",
        "        impostors_a, impostors_b, impostors_y = get_impostors()\n",
        "        a = np.append(genuines_a, impostors_a, axis=0)\n",
        "        b = np.append(genuines_b, impostors_b, axis=0)\n",
        "        y = np.append(genuines_y, impostors_y, axis=0)\n",
        "        \n",
        "        batch_h5 = h5.File(os.path.join(self.__name__, f'b{index}.h5'), 'a')\n",
        "        batch_h5.create_dataset('a', data=a)\n",
        "        batch_h5.create_dataset('b', data=b)\n",
        "        batch_h5.create_dataset('y', data=y)\n",
        "        \n",
        "        return ([batch_h5['a'], batch_h5['b']], batch_h5['y'])\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        return self.__batches__[index]   \n",
        "      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_rjMi1hvrZw"
      },
      "source": [
        "We use ResNet50 as an encoder, just adding an extra linear layer. Feature vectors have 100 entries (features).\n",
        "The following cell defines the function that creates the encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juulpMQkvrZx"
      },
      "outputs": [],
      "source": [
        "def build_resnet50_encoder(n_features=100):\n",
        "    base_model = ResNet50(weights=None, include_top=False, input_shape=(80,80,3))\n",
        "    x = base_model.output\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(0.7)(x)\n",
        "    x = layers.Dense(n_features, activation='linear')(x)\n",
        "    model = keras.Model(inputs = base_model.input, outputs = x)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5LB_GrYvrZy"
      },
      "source": [
        "The next cell creates the SNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUk4t5msvrZz"
      },
      "outputs": [],
      "source": [
        "my_snn = SNN((80,80,3),build_resnet50_encoder())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECRM2X6yvrZ0"
      },
      "source": [
        "The next cell creates the generators and trains the SNN.\n",
        "\n",
        "The loss function used is the **Contrastive Loss**, proposed by Lian et al in 2018.\n",
        "\n",
        "$$L(y,d)= yd^2 + (1-y)\\max\\{m-d,0\\}^2$$\n",
        "\n",
        "Where:\n",
        "* $y$ is the label (**1** for genuine pairs and **0** for impostor pairs).\n",
        "* $d$ is the euclidean distance between $a$ and $b$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixuTXO28vrZ0"
      },
      "outputs": [],
      "source": [
        "training_generator = CelebAGenerator('training_batches', training_genuine_pairs, training_impostor_pairs, 100)\n",
        "eval_generator = CelebAGenerator('eval_batches', eval_genuine_pairs, eval_impostor_pairs, 100)\n",
        "my_snn.fit(training_generator, eval_generator, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell plots the evolution of the training loss and the validation loss over the course of training."
      ],
      "metadata": {
        "id": "yMuIZ61XU2DM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([i+1 for i in range(len(my_snn.training_loss_history))], my_snn.training_loss_history, label='Training')\n",
        "plt.plot([i+1 for i in range(len(my_snn.validation_loss_history))], my_snn.validation_loss_history, label='Validation')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')  \n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MRFVottlS3mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLCTM_TTvrZ1"
      },
      "source": [
        "The next cell saves encoder's weights to a file. We will use this encoder later as part of a prediction framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCE6bXPTvrZ2"
      },
      "outputs": [],
      "source": [
        "my_snn.save_encoder('resnet50_encoder_weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If you're on Google Colab, don't forget to download the file *resnet50_encoder_weights.h5* as it will be needed to run the other notebooks.**"
      ],
      "metadata": {
        "id": "QiVLaEqvwW5m"
      }
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "0b0c1afb09a890ec0f70a52038241e9984908d1a33ff4685df2a9c777506c484"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 ('ds')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "training.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}